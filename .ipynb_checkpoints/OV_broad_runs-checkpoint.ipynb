{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of COSMIC genes  3959\n",
      "Num COSMIC genes in this cancer 555\n",
      "4\n",
      "6\n",
      "[4, 6]\n"
     ]
    }
   ],
   "source": [
    "import mutex as mex\n",
    "import csv\n",
    "\n",
    "mutationmatrix = '/Users/jlu96/maf/new/OV_broad/OV_broad-cna-jl.m2'\n",
    "patientFile = '/Users/jlu96/maf/new/OV_broad/shared_patients.plst'\n",
    "geneFile = None\n",
    "minFreq = 0\n",
    "COSMICFile = '/Users/jlu96/conte/jlu/Analyses/CancerGeneAnalysis/COSMIC/COSMICGenes_OnlyLoss.txt'\n",
    "closer_than_distance = 10000000\n",
    "partition_file = '/Users/jlu96/maf/new/OV_broad/OV_broad-cna-jl.ppf9'\n",
    "load_pmm_file = '/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/OV_broad-cna-jl-PMM.txt'\n",
    "dna_pmm_comparison_file = '/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/OV_broad-cna-jl-PMM-dnacomp.txt'\n",
    "\n",
    "numGenes, numCases, genes, patients, geneToCases, patientToGenes = mex.load_mutation_data(mutationmatrix, patientFile, geneFile, minFreq)\n",
    "\n",
    "if COSMICFile:\n",
    "    COSMICgenes = set()\n",
    "    with open(COSMICFile, 'rU') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            COSMICgenes.add(*row)\n",
    "    print \"Number of COSMIC genes \", len(COSMICgenes)\n",
    "    genes = (set(genes)).intersection(COSMICgenes)\n",
    "    geneToCases = dict([g for g in geneToCases.items() if g[0] in genes])\n",
    "\n",
    "print \"Num COSMIC genes in this cancer\", len(genes)\n",
    "            \n",
    "\n",
    "\n",
    "cohort_dict, clusterToProp, min_cohort = load_patient_cohorts(partition_file, patientToGenes)\n",
    "\n",
    "print clusterToProp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number genes is  543\n",
      "number patients is  70\n",
      "Mean is  [7556.5, 8829.3, 475.0, 2310.0, 3942.4, 5780.8]\n",
      "['HEY1loss', 'CD79Bloss', 'KAT6Aloss', 'PPFIBP1loss', 'PRDM1loss', 'HSP90AA1loss', 'NUP214loss', 'TCL1Aloss', 'HOXA9loss', 'USP6loss', 'HMGN2P46loss', 'PMS1loss', 'UBR5loss', 'SETD2loss', 'MDM2loss', 'ZCCHC8loss', 'GATA2loss', 'HNF1Aloss', 'MAP2K2loss', 'FOXO1loss', 'SRSF2loss', 'CNTRLloss', 'CDX2loss', 'LIFRloss', 'SMARCB1loss', 'HLFloss', 'TFRCloss', 'MN1loss', 'SND1loss', 'MYO5Aloss']\n",
      "Number of genes in cluster 0:  543\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEKCAYAAAD6q1UVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1250f18d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEKCAYAAAAPVd6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1115cf710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top gene frequencies are  [58, 57, 57, 57, 56, 55, 55, 55, 55, 54]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEKCAYAAAAPVd6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMyucE7mZWeGcyM3MCudEbmZWuP8HWJIuD2hsbD8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b49d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top gene frequencies are  [68, 68, 67, 67, 66, 65, 65, 65, 64, 64]\n",
      "numbr of genes used is  22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# let's look at the smallest cluster\n",
    "c0patients = clusterToProp[4]['Patients']\n",
    "c1patients = clusterToProp[6]['Patients']\n",
    "\n",
    "c0genes, c0geneToCases, c0patientToGenes = get_cluster_gTC_pTG(geneToCases, patientToGenes, c0patients)\n",
    "c1genes, c1geneToCases, c1patientToGenes = get_cluster_gTC_pTG(geneToCases, patientToGenes, c1patients)\n",
    "\n",
    "print \"number genes is \", len(c0genes)\n",
    "print \"number patients is \", len(c0patients)\n",
    "print \"Mean is \", clusterToProp[4]['Mean']\n",
    "print list(c0genes)[0:30]\n",
    "print \"Number of genes in cluster 0: \", len(c0genes)\n",
    "\n",
    "\n",
    "\n",
    "pfreq = [len(c0patientToGenes[p]) for p in c0patients]\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "plt.hist(pfreq, 100)\n",
    "plt.title(\"Patient Mutation Frequencies in first cluster\")\n",
    "plt.show()\n",
    "\n",
    "gfreq = [len(c0geneToCases[g]) for g in c0geneToCases]\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "plt.hist(gfreq, 100)\n",
    "plt.title(\"Gene Mutation Frequencies in first cluster\")\n",
    "plt.show()\n",
    "\n",
    "print \"Top gene frequencies are \", sorted(gfreq, reverse=True)[0:10]\n",
    "\n",
    "gfreq = [len(c1geneToCases[g]) for g in c1geneToCases]\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "plt.hist(gfreq, 100)\n",
    "plt.title(\"Gene Mutation Frequencies in second cluster\")\n",
    "plt.show()\n",
    "\n",
    "print \"Top gene frequencies are \", sorted(gfreq, reverse=True)[0:10]\n",
    "# let's limit to the genes with at least \n",
    "\n",
    "test_minFreq = 50\n",
    "test_genes = [c for c in c0genes if len(c0geneToCases[c]) >= test_minFreq]\n",
    "print \"numbr of genes used is \", len(test_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs to test:  193\n",
      "Number of pairs is  193\n",
      "number of pairs is  193\n",
      "Original pairs  193 . Min cohort pairs:  193\n",
      "Writing to file...\n"
     ]
    }
   ],
   "source": [
    "import mutex_triangles as met\n",
    "import chisquared as chi\n",
    "import bingenesbypairs as bgbp\n",
    "compute_mutex = True\n",
    "\n",
    "cpairfile = '/Users/jlu96/conte/jlu/Analyses/CooccurImprovement/LorenzoModel/Binomial/OV_broad-cna-jl-cpairs-min_cohort.txt'\n",
    "\n",
    "\n",
    "\n",
    "genepairs = bgbp.getgenepairs(c0geneToCases, test_genes, test_minFreq=test_minFreq, closer_than_distance=closer_than_distance)\n",
    "print \"Number of pairs is \", len(genepairs)\n",
    "\n",
    "cpairsdict, cgenedict = met.cooccurpairs(numCases, geneToCases, patientToGenes, genepairs, compute_mutex=compute_mutex)\n",
    "\n",
    "print \"number of pairs is \", len(cpairsdict)\n",
    "cpairsdict = chi.add_BinomP_min_cohort_all_pairs(cpairsdict, geneToCases, patientToGenes, cohort_dict, cohort_dict[4])\n",
    "\n",
    "print \"Writing to file...\"\n",
    "\n",
    "fieldnames = (cpairsdict.values()[0]).keys()\n",
    "fieldnames.remove('Type')\n",
    "fieldnames.remove('MutationFrequencies')\n",
    "fieldnames.remove('MutationFrequencyDifference')\n",
    "fieldnames.remove('MutationFrequencyDifferenceRatio')\n",
    "fieldnames.remove('CooccurrenceRatio')\n",
    "fieldnames.remove('Coverage')\n",
    "fieldnames.remove('SetScore')\n",
    "fieldnames.remove('AverageOverlapPMN')\n",
    "fieldnames.remove('CombinedScore')\n",
    "fieldnames.remove('Concordance')\n",
    "fieldnames.remove('Somatic')\n",
    "fieldnames.remove('RoundedLogPCov')\n",
    "fieldnames.remove('GeneSet')\n",
    "\n",
    "\n",
    "met.writeanydict(cpairsdict, cpairfile, fieldnames=fieldnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below uses the bottom 15 %, least mutated patients\n",
    "# It filters to those genes mutated in 10% of those patients\n",
    "# It uses segmentation\n",
    "# OV_broad has ~5000 segments, unlike BRCA's ~2000. Let's see how well we do under multiple testing: do many end up significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new patients is  21\n",
      "number genes in smallest cluster is  4505\n",
      "number of genes above threashold  3499\n",
      "number patients is  21\n",
      "Number of pairs to test:  5840495\n",
      "Number of pairs is  5840495  retrieved in time :  66.9682569504\n"
     ]
    }
   ],
   "source": [
    "# Build this so that it takes all patients within the farthest cluster\n",
    "\n",
    "import mutex as mex\n",
    "import csv\n",
    "import mutex_triangles as met\n",
    "import chisquared as chi\n",
    "import bingenesbypairs as bgbp\n",
    "import time\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import partition as par\n",
    "\n",
    "\n",
    "cancer = 'OV_broad'\n",
    "suffix = '-seg-jl'\n",
    "top_folder = '/Users/jlu96/maf/new/'\n",
    "mutationmatrix = top_folder + cancer + '/' + cancer + suffix + '.m2'\n",
    "patientFile = top_folder + cancer + 'shared_patients.plst'\n",
    "partition_file = top_folder + cancer + '/' + cancer + '-cna-jl.ppf'\n",
    "segment_info_file = top_folder + cancer + \"/segment_info.txt\"\n",
    "file_prefix = '/Users/jlu96/conte/jlu/Analyses/CooccurImprovement/LorenzoModel/Binomial/' + cancer + suffix\n",
    "cpairfile = file_prefix + '-cpairs-min_cohort.txt'\n",
    "triplet_file_prefix = file_prefix + '-triplet-'\n",
    "new_cpairfile = file_prefix + \"-cpairs-min_cohort_filtered.txt\"\n",
    "geneFile = None\n",
    "minFreq = 0\n",
    "compute_mutex = True\n",
    "closer_than_distance = 100000000\n",
    "test_minFreq = 0.1\n",
    "minPercentile = 15\n",
    "cpairPercentile = 1\n",
    "mpairPercentile = 1\n",
    "pthresh = 0.05\n",
    "use_whole_partition = False\n",
    "\n",
    "\n",
    "numGenes, numCases, genes, patients, geneToCases, patientToGenes = mex.load_mutation_data(mutationmatrix, patientFile, geneFile, minFreq)\n",
    "\n",
    "D = [len(patientToGenes[p]) for p in patientToGenes]\n",
    "minThreshold = stats.scoreatpercentile(D, minPercentile)\n",
    "\n",
    "c0patients = set([p for p in patientToGenes if len(patientToGenes[p]) <= minThreshold])\n",
    "\n",
    "if use_whole_partition:\n",
    "    cohort_dict, clusterToProp, min_cohort = load_patient_cohorts(partition_file, patientToGenes)\n",
    "    max_cluster = max([c for c in cohort_dict if cohort_dict[c].intersection(c0patients)])\n",
    "    print \"Largest cluster containing is \", max_cluster, \" with mean \", clusterToProp[i]['Mean']\n",
    "    c0patients = set(c0patients).add(cohort_dict[max_cluster])\n",
    "\n",
    "print \"Number of new patients is \", len(c0patients)\n",
    "\n",
    "\n",
    "test_minFreq = int( test_minFreq * len(c0patients))\n",
    "c0cohort_dict = {0: c0patients}\n",
    "c0genes, c0geneToCases, c0patientToGenes = par.get_cluster_gTC_pTG(geneToCases, patientToGenes, c0patients)\n",
    "\n",
    "print \"number genes in smallest cluster is \", len(c0genes)\n",
    "print \"number of genes above threashold \", len([g for g in c0genes if len(c0geneToCases[g]) >= test_minFreq])\n",
    "print \"number patients is \", len(c0patients)\n",
    "\n",
    "t = time.time()\n",
    "genepairs = bgbp.getgenepairs(c0geneToCases, c0genes, test_minFreq=test_minFreq, closer_than_distance=closer_than_distance)\n",
    "print \"Number of pairs is \", len(genepairs), \" retrieved in time : \", time.time() - t\n",
    "\n",
    "cpairsdict, cgenedict = met.cooccurpairs(numCases, geneToCases, patientToGenes, genepairs, compute_mutex=compute_mutex)\n",
    "\n",
    "print \"number of pairs is \", len(cpairsdict)\n",
    "print \"Getting cooccurrence across the whole distribution\"\n",
    "\n",
    "cpairsdict = chi.add_BinomP_cohorts_all_pairs(cpairsdict, geneToCases, patientToGenes, c0cohort_dict, c0patients)\n",
    "\n",
    "# cpairsdict = chi.add_BinomP_all_pairs(cpairsdict, geneToCases, patientToGenes)\n",
    "print \"Writing to file...\"\n",
    "\n",
    "fieldnames = (cpairsdict.values()[0]).keys()\n",
    "fieldnames.remove('Type')\n",
    "fieldnames.remove('MutationFrequencies')\n",
    "fieldnames.remove('MutationFrequencyDifference')\n",
    "fieldnames.remove('MutationFrequencyDifferenceRatio')\n",
    "fieldnames.remove('CooccurrenceRatio')\n",
    "fieldnames.remove('Coverage')\n",
    "fieldnames.remove('SetScore')\n",
    "fieldnames.remove('AverageOverlapPMN')\n",
    "fieldnames.remove('CombinedScore')\n",
    "fieldnames.remove('Concordance')\n",
    "fieldnames.remove('Somatic')\n",
    "fieldnames.remove('RoundedLogPCov')\n",
    "fieldnames.remove('GeneSet')\n",
    "\n",
    "met.writeanydict(cpairsdict, cpairfile, fieldnames=fieldnames)\n",
    "os.system('say \"finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpvalues = np.array([cpairsdict[c]['1CBinomProb0'] for c in cpairsdict])\n",
    "logcp = np.log(cpvalues)\n",
    "\n",
    "threshold = pthresh/len(logcp)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(logcp, bins=50)\n",
    "plt.title(\"Distribution of log p-values\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mpvalues = np.array([cpairsdict[c]['1MBinomProb0'] for c in cpairsdict])\n",
    "logmp = np.log(mpvalues)\n",
    "\n",
    "threshold = pthresh/len(logmp)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(logmp, bins=50)\n",
    "plt.title(\"Distribution of log p-values\")\n",
    "plt.show()\n",
    "\n",
    "cthreshold = stats.scoreatpercentile(cpvalues, cpairPercentile)\n",
    "mthreshold = stats.scoreatpercentile(mpvalues, mpairPercentile)\n",
    "print \"Top \", cpairPercentile, \"percent of cooccurring pairs: \", cthreshold\n",
    "print \"Top \", mpairPercentile, \"percent of mutually exclusive pairs : \", mthreshold\n",
    "\n",
    "# Let's get the top 10 percent of pairs\n",
    "\n",
    "goodpairs = [c for c in cpairsdict if (cpairsdict[c]['1CBinomProb0'] <= cthreshold or cpairsdict[c]['1MBinomProb0'] <= mthreshold)]\n",
    "print \"Now number of pairs to test \", len(goodpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_cpairsdict, new_cgenedict = met.cooccurpairs(numCases, geneToCases, patientToGenes, goodpairs, compute_mutex=compute_mutex)\n",
    "\n",
    "print \"number of pairs is \", len(new_cpairsdict)\n",
    "print \"Getting cooccurrence across the whole distribution\"\n",
    "\n",
    "new_cpairsdict = chi.add_BinomP_cohorts_all_pairs(new_cpairsdict, geneToCases, patientToGenes, c0cohort_dict, c0patients)\n",
    "new_cpairsdict = chi.add_BinomP_all_pairs(new_cpairsdict, geneToCases, patientToGenes)\n",
    "print \"Writing to file at \", new_cpairfile\n",
    "\n",
    "fieldnames = (new_cpairsdict.values()[0]).keys()\n",
    "fieldnames.remove('Type')\n",
    "fieldnames.remove('MutationFrequencies')\n",
    "fieldnames.remove('MutationFrequencyDifference')\n",
    "fieldnames.remove('MutationFrequencyDifferenceRatio')\n",
    "fieldnames.remove('CooccurrenceRatio')\n",
    "fieldnames.remove('Coverage')\n",
    "fieldnames.remove('SetScore')\n",
    "fieldnames.remove('AverageOverlapPMN')\n",
    "fieldnames.remove('CombinedScore')\n",
    "fieldnames.remove('Concordance')\n",
    "fieldnames.remove('Somatic')\n",
    "fieldnames.remove('RoundedLogPCov')\n",
    "fieldnames.remove('GeneSet')\n",
    "\n",
    "met.writeanydict(new_cpairsdict, new_cpairfile, fieldnames=fieldnames)\n",
    "os.system('say \"finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the p-value distribution\n",
    "pvalues = np.array([new_cpairsdict[c]['BinomProbability'] for c in new_cpairsdict])\n",
    "logp = np.log(pvalues)\n",
    "\n",
    "threshold = 0.05/len(logp)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(logp, bins=50)\n",
    "plt.title(\"Distribution of log p-values\")\n",
    "plt.axvline(x=np.log(threshold), ymin=0, ymax=1000)\n",
    "plt.show()\n",
    "\n",
    "sig = [pvalue for pvalue in pvalues if pvalue < threshold]\n",
    "print \"Number of significant pairs \", len(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the segment infos\n",
    "\n",
    "bgbp.write_segment_infos(c0genes, segment_info_file)\n",
    "\n",
    "for pair in new_cpairsdict:\n",
    "    info0 = bgbp.get_segment_gene_info(new_cpairsdict[pair]['Gene0'])\n",
    "    new_cpairsdict[pair]['Gene0Loc'] = str(info0['Chromosome']) + ':' + str(info0['Start'])\n",
    "    info1 = bgbp.get_segment_gene_info(new_cpairsdict[pair]['Gene1'])\n",
    "    new_cpairsdict[pair]['Gene1Loc'] = str(info1['Chromosome']) + ':' + str(info1['Start'])\n",
    "    \n",
    "fieldnames += ['Gene0Loc', 'Gene1Loc']\n",
    "print \"Writing to file at \", new_cpairfile\n",
    "met.writeanydict(new_cpairsdict, new_cpairfile, fieldnames=fieldnames)\n",
    "os.system('say \"finished\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the co-occurrence/ mutual exclusivity. Is it good? Are they near each other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'jlu96'\n",
    "import mutex as mex\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy.stats import poisson\n",
    "from scipy import stats\n",
    "import collections\n",
    "import os\n",
    "\n",
    "def partition_EM(patientToGenes, k):\n",
    "    \"\"\"\n",
    "    :param geneToCases:\n",
    "    :param patientToGenes:\n",
    "    :param k: Number of partitions\n",
    "    :return: cohort_list\n",
    "    \"\"\"\n",
    "\n",
    "    # partition the patients, and intersect the geneToCases\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def partition_gene(patientToGenes, genes):\n",
    "    \"\"\"\n",
    "    :param geneToCases:\n",
    "    :param patientToGenes:\n",
    "    :param genes:\n",
    "    :return: cohorts by each gene. Size 2^(#genes)\n",
    "    \"\"\"\n",
    "\n",
    "    cohorts = [patientToGenes.keys()]\n",
    "    for gene in genes:\n",
    "        new_cohorts = []\n",
    "        for cohort in cohorts:\n",
    "            new_cohort_1 = [patient for patient in patientToGenes if gene not in patientToGenes[patient]]\n",
    "            if new_cohort_1:\n",
    "                new_cohorts.append(new_cohort_1)\n",
    "            new_cohort_2 = list(set(cohort).difference(set(new_cohort_1)))\n",
    "            if new_cohort_2:\n",
    "                new_cohorts.append(new_cohort_2)\n",
    "        cohorts = new_cohorts\n",
    "    # print genes\n",
    "    # print cohorts\n",
    "\n",
    "    return cohorts\n",
    "\n",
    "def partition_gene_list(patientToGenes, genes, binary=True):\n",
    "    \"\"\"\n",
    "    :param patientToGenes:\n",
    "    :param genes:\n",
    "    :return: The cohorts, ordered from least to greatest in number of those genes they have.\n",
    "    If binary = True, return just those with, those without.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    gene_set = set(genes)\n",
    "    cohort_dict = {}\n",
    "\n",
    "    for patient in patientToGenes:\n",
    "        num = len(set.intersection(gene_set, patientToGenes[patient]))\n",
    "\n",
    "        # just 0 and 1\n",
    "        if binary:\n",
    "            if num > 0:\n",
    "                num = 1\n",
    "\n",
    "        if num not in cohort_dict:\n",
    "            cohort_dict[num] = []\n",
    "        cohort_dict[num].append(patient)\n",
    "\n",
    "\n",
    "    return cohort_dict\n",
    "\n",
    "\n",
    "def get_patients_gene_mut_num(patients, genes, patientToGenes):\n",
    "    return [set.intersection(patientToGenes[p], genes) for p in patients]\n",
    "\n",
    "def integrate_cohorts(cohort_dict, numCases, num_integrated):\n",
    "    cohorts_int = {}\n",
    "    start_index = 0\n",
    "    num_in_cohort = 0\n",
    "    new_cohort = []\n",
    "    for i in cohort_dict.keys():\n",
    "        num_in_cohort += len(cohort_dict[i])\n",
    "        new_cohort.extend(cohort_dict[i])\n",
    "        if (num_in_cohort > numCases/num_integrated):\n",
    "            cohorts_int[start_index] = new_cohort\n",
    "            start_index = i+1\n",
    "            new_cohort = []\n",
    "            num_in_cohort = 0\n",
    "\n",
    "    if new_cohort:\n",
    "        cohorts_int[start_index] = new_cohort\n",
    "\n",
    "    return cohorts_int\n",
    "\n",
    "def integrate_cohorts_sizes(cohort_dict, sizes):\n",
    "    cohorts_int = {}\n",
    "    size_index = 0\n",
    "    num_in_cohort = 0\n",
    "    new_cohort = []\n",
    "    for i in cohort_dict.keys():\n",
    "        num_in_cohort += len(cohort_dict[i])\n",
    "        new_cohort.extend(cohort_dict[i])\n",
    "        if (num_in_cohort > sizes[size_index]):\n",
    "            cohorts_int[size_index] = new_cohort\n",
    "            size_index += 1\n",
    "            new_cohort = []\n",
    "            num_in_cohort = 0\n",
    "\n",
    "    if new_cohort:\n",
    "        cohorts_int[size_index] = new_cohort\n",
    "\n",
    "    return cohorts_int\n",
    "\n",
    "\n",
    "def draw_partitions_cohorts(geneToCases, patientToGenes, cohort_pairings, title=None, num_bins=50):\n",
    "    # LEFT OF HERE, JLU. Finish this, then above. Make plots in parallel, compare.\n",
    "    # Work with: TP53? Others?\n",
    "\n",
    "    numGenes = len(geneToCases.keys())\n",
    "    numCohorts = len(cohort_pairings)\n",
    "\n",
    "    cohort_frequencies = [[len(patientToGenes[case]) for case in cohort_pair[1]] for cohort_pair in cohort_pairings]\n",
    "    cohort_names = [cohort_pair[0] for cohort_pair in cohort_pairings]\n",
    "\n",
    "    draw_partitions(patientToGenes, cohort_names, cohort_frequencies, title=title, num_bins=num_bins)\n",
    "\n",
    "\n",
    "def draw_partitions(patientToGenes, cohort_names, cohort_frequencies, title=None, num_bins=50):\n",
    "\n",
    "    numCohorts = len(cohort_frequencies)\n",
    "    bins = range(0, max([len(p_gene) for p_gene in patientToGenes.values()]), max([len(p_gene) for p_gene in patientToGenes.values()])/num_bins)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "    for i in range(len(cohort_frequencies)):\n",
    "        plt.hist(cohort_frequencies[i], bins, alpha=1.0/numCohorts, label=str(cohort_names[i]))\n",
    "\n",
    "\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel('# Somatic Mutations In Tumor', fontsize=20)\n",
    "    plt.ylabel('Number of Samples', fontsize=20)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def norm(x, height, center, std):\n",
    "    return(height*np.exp(-(x - center)**2/(2*std**2)))\n",
    "\n",
    "\n",
    "\n",
    "def partition_GMM(patientToGenes, num_components, num_bins, title=None, do_plot=True):\n",
    "    g = mixture.GMM(n_components=num_components)\n",
    "    mut_num_list = [len(patientToGenes[p]) for p in patientToGenes]\n",
    "    obs = np.array([[entry] for entry in mut_num_list])\n",
    "    g.fit(obs)\n",
    "\n",
    "    print \"***********************************\"\n",
    "    print \"COMPONENTS: \", num_components\n",
    "    print \"Weights: \" + str(np.round(g.weights_,2))\n",
    "    print \"Means: \" + str(np.round(g.means_,2))\n",
    "    print \"Covariates: \" + str(np.round(g.covars_,2))\n",
    "\n",
    "    print \"Total log probability: \" + str(sum(g.score(obs)))\n",
    "    print \"AIC: \" + str(g.aic(obs))\n",
    "    print \"BIC: \", g.bic(obs)\n",
    "\n",
    "    score, respon = g.score_samples(obs)\n",
    "\n",
    "    for i in range(num_components):\n",
    "        print \"Model \", np.round(g.means_, 2)[i], \" explains \", np.round(len([in_w for in_w in respon if in_w[i] == max(in_w)])) * 1.0 /len(respon)\n",
    "\n",
    "\n",
    "    # Simulate gaussians\n",
    "    # sim_samples = g.sample(len(patientToGenes))\n",
    "    bins = range(0, max([len(p_gene) for p_gene in patientToGenes.values()]), max([len(p_gene) for p_gene in patientToGenes.values()])/num_bins)\n",
    "    histogram = np.histogram([len(patientToGenes[p]) for p in patientToGenes], bins=bins)\n",
    "\n",
    "    # get the scale of the gaussians from the biggest one\n",
    "    # max_comp = g.weights_.index(max(g.weights_))\n",
    "    # max_mean = g.means_[max_comp]\n",
    "\n",
    "    which_bins = [[bin for bin in bins if bin > mean][0] for mean in g.means_]\n",
    "    print which_bins\n",
    "    print bins\n",
    "    print histogram\n",
    "    print bins.index(which_bins[0]) - 1\n",
    "    bin_heights = [histogram[0][bins.index(which_bin) - 1] for which_bin in which_bins]\n",
    "    # max_height = max(histogram)\n",
    "\n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.hist([len(patientToGenes[p]) for p in patientToGenes], bins=bins)\n",
    "        for i in range(num_components):\n",
    "            X = np.arange(0, max(mut_num_list), 1)\n",
    "            Y = norm(X, bin_heights[i], g.means_[i], np.sqrt(g.covars_[i]))\n",
    "            plt.plot(X, Y, label=str(np.round(g.weights_[i], 3)), linewidth=5)\n",
    "        plt.title(\"GMM size \" + str(num_components), fontsize=20)\n",
    "        plt.xlabel('# Somatic Mutations In Tumor', fontsize=20)\n",
    "        plt.ylabel('Number of Samples', fontsize=20)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # draw_partitions(patientToGenes, ['Original', 'Simulated'], [[len(patientToGenes[p]) for p in patientToGenes], sim_samples],\n",
    "        #                 num_bins=num_bins, title=title)\n",
    "\n",
    "    data = {}\n",
    "    data['Components'] = num_components\n",
    "    data['Weights'] = np.round(g.weights_,2)\n",
    "    data['Means'] = np.round(g.means_,2)\n",
    "    # data['Covariates'] = np.round(g.covars_,2)\n",
    "    # data[\"Total log probability\"] = sum(g.score(obs))\n",
    "    data[\"AIC\"] = g.aic(obs)\n",
    "    data[\"BIC\"] = g.bic(obs)\n",
    "    data['Explained'] = [np.round([len([in_w for in_w in respon if in_w[i] == max(in_w)]) * 1.0 /len(respon) for i in range(num_components)], 2)]\n",
    "\n",
    "    return data\n",
    "\n",
    "def partition_gene_kmeans(geneToCases, patientToGenes, gene_list, num_components, num_bins, title=None, do_plot=True):\n",
    "\n",
    "    # get gene index mapping\n",
    "    giv = getgiv(geneToCases.keys(), gene_list)\n",
    "\n",
    "    # convert patients into vectors\n",
    "    patientToVector = getpatientToVector(patientToGenes, giv)\n",
    "\n",
    "    vectors = patientToVector.values()\n",
    "\n",
    "    print vectors[0]\n",
    "    print \"Length of vectors is \", len(vectors[0])\n",
    "\n",
    "    km = KMeans(num_components)\n",
    "\n",
    "    km.fit(vectors)\n",
    "\n",
    "    clusterToPatient = {}\n",
    "\n",
    "    for patient in patientToVector:\n",
    "        cluster = km.predict(patientToVector[patient])[0]\n",
    "        if cluster not in clusterToPatient:\n",
    "            clusterToPatient[cluster] = set()\n",
    "        clusterToPatient[cluster].add(patient)\n",
    "\n",
    "    # plot patients in each cluster\n",
    "\n",
    "\n",
    "    if do_plot:\n",
    "        bins = range(0, max([len(p_gene) for p_gene in patientToGenes.values()]), max([len(p_gene) for p_gene in patientToGenes.values()])/num_bins)\n",
    "        plt.figure()\n",
    "        for cluster in clusterToPatient:\n",
    "            plt.hist([len(patientToGenes[p]) for p in clusterToPatient[cluster]], bins=bins, label=str(cluster), alpha = 1.0/num_components)\n",
    "        plt.xlabel('# Somatic Mutations In Tumor', fontsize=20)\n",
    "        plt.ylabel('Number of Samples', fontsize=20)\n",
    "        plt.legend()\n",
    "        plt.title(\"Kmeans size \" + str(num_components), fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    data = {}\n",
    "    data['Score'] = km.score(vectors)\n",
    "    data['Number'] = num_components\n",
    "    data['% Explained'] = np.round([100 * len(clusterToPatient[cluster]) * 1.0 / len(patientToGenes) for cluster in clusterToPatient], 2)\n",
    "    data['Vector size'] = len(vectors[0])\n",
    "    # data['Covariates'] = np.round(g.covars_,2)\n",
    "    # data[\"Total log probability\"] = sum(g.score(obs))\n",
    "    # data[\"AIC\"] = g.aic(obs)\n",
    "    # data[\"BIC\"] = g.bic(obs)\n",
    "    # data['Explained'] = [np.round([len([in_w for in_w in respon if in_w[i] == max(in_w)]) * 1.0 /len(respon) for i in range(num_components)], 2)]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def getgiv(all_genes, gene_list):\n",
    "    \"\"\"\n",
    "    :param all_genes:\n",
    "    :param gene_list:\n",
    "    :return: A list of the genes in common, the gene_index_vector.\n",
    "    \"\"\"\n",
    "    giv = list(set(all_genes).intersection(set(gene_list)))\n",
    "\n",
    "    return giv\n",
    "\n",
    "\n",
    "\n",
    "def getpatientToVector(patientToGenes, gene_index_vector):\n",
    "    patientToVector = {}\n",
    "    for patient in patientToGenes:\n",
    "        patient_genes = patientToGenes[patient]\n",
    "        patientToVector[patient] = []\n",
    "        for gene in gene_index_vector:\n",
    "            patientToVector[patient].append(1 if gene in patient_genes else 0)\n",
    "\n",
    "    return patientToVector\n",
    "\n",
    "\n",
    "def get_cluster_gTC_pTG(geneToCases, patientToGenes, patients):\n",
    "    new_pTG = dict([c for c in patientToGenes.items() if c[0] in patients])\n",
    "    new_genes = set.union(*new_pTG.values())\n",
    "    new_gTC = dict([g for g in geneToCases.items() if g[0] in new_genes])\n",
    "    for g in new_gTC:\n",
    "        new_gTC[g] = new_gTC[g].intersection(patients)\n",
    "    \n",
    "    for g in new_genes:\n",
    "        if g in new_gTC and not new_gTC[g]:\n",
    "            new_gTC.pop(g)\n",
    "    \n",
    "    new_genes = new_genes.intersection(set(new_gTC.keys()))\n",
    "    \n",
    "    return new_genes, new_gTC, new_pTG\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3/12/16-Jlu\n",
    "\n",
    "\n",
    "class PMM:\n",
    "\n",
    "    def __init__(self, filename=None, delimiter='\\t', lam=None, p_k=None, classes=None, patientToGenes=None,\n",
    "                data = None, clusterToPatient = None, do_fit=True):\n",
    "\n",
    "        if filename:\n",
    "            with open(filename, 'rU') as csvfile:\n",
    "                reader = csv.DictReader(csvfile, delimiter=delimiter)\n",
    "                row = reader.next()\n",
    "                print row\n",
    "                self.lam = eval(row['Means'])\n",
    "                self.p_k = eval(row['Probabilities'])\n",
    "                self.classes = eval(row['Classes']) if 'Classes' in row else range(len(self.lam))\n",
    "                self.num_components = len(self.classes)\n",
    "        else:\n",
    "            self.lam = lam\n",
    "            self.p_k = p_k\n",
    "            self.classes = classes\n",
    "            if not classes:\n",
    "                self.classes = range(len(self.lam))\n",
    "            self.num_components = len(self.classes)\n",
    "\n",
    "\n",
    "        self.data = data\n",
    "        self.clusterToPatient = clusterToPatient\n",
    "        print \"Class is \", self.classes, \"Keys are \", self.clusterToPatient.keys()\n",
    "\n",
    "        self.patientToGenes = patientToGenes\n",
    "\n",
    "        if patientToGenes and do_fit:\n",
    "            self.fit_to_data(patientToGenes)\n",
    "\n",
    "    def fit_to_data(self, patientToGenes, min_cluster_size=0):\n",
    "        self.patientToGenes = patientToGenes\n",
    "        self.data, self.clusterToPatient = pmm_fit_to_data(patientToGenes, classes=self.classes, lam=self.lam, p_k=self.p_k,\n",
    "                                                           min_cluster_size=min_cluster_size)\n",
    "        return self.data, self.clusterToPatient\n",
    "\n",
    "\n",
    "    def plot_clusters(self, title):\n",
    "        plot_pmm_clusters(self.patientToGenes, self.clusterToPatient, self.num_components, title=title)\n",
    "\n",
    "\n",
    "    def write_clusters(self, partition_file):\n",
    "        with open(partition_file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "\n",
    "            writer.writerow(['Likelihood', self.data['Likelihood']])\n",
    "            writer.writerow(['BIC', self.data['BIC']])\n",
    "            writer.writerow(['NumComponents', self.data['Number']])\n",
    "            writer.writerow(['Cluster', 'Lambda', 'Probability', 'Patients'])\n",
    "            for k in self.clusterToPatient:\n",
    "                if k != -1:\n",
    "                    lam = self.data['Means'][k]\n",
    "                    p_k = self.data['Probabilities'][k]\n",
    "                else:\n",
    "                    lam = None\n",
    "                    p_k = None\n",
    "                writer.writerow([k, lam, p_k] + list(self.clusterToPatient[k]))\n",
    "\n",
    "    def compare_dna(self, dna_cohort_dict, do_KS=False):\n",
    "\n",
    "        partition_stats_list = []\n",
    "\n",
    "        sizes = [len(self.clusterToPatient[c]) for c in self.clusterToPatient]\n",
    "\n",
    "        # partition by genes\n",
    "        dna_cohorts = integrate_cohorts_sizes(dna_cohort_dict, sizes)\n",
    "\n",
    "        pmm_cluster_list = []\n",
    "        dna_cluster_list = []\n",
    "        \n",
    "        print \"In partition stats Class is \", self.classes, \"Keys are \", self.clusterToPatient.keys()\n",
    "        \n",
    "        for i in range(len(self.classes)):\n",
    "            partition_stats = collections.OrderedDict()\n",
    "            partition_stats['Class'] = self.classes[i]\n",
    "            partition_stats['Mean'] = self.lam[i]\n",
    "            partition_stats['Probability'] = self.p_k[i]\n",
    "\n",
    "\n",
    "            partition_stats['PMM_patients'] = self.clusterToPatient[self.classes[i]]\n",
    "            partition_stats['DNA_patients'] = dna_cohorts[i]\n",
    "\n",
    "            pmm_cluster_list.append(partition_stats['PMM_patients'])\n",
    "            dna_cluster_list.append(partition_stats['DNA_patients'])\n",
    "            \n",
    "            dna_pmn = [len(self.patientToGenes[p]) for p in partition_stats['DNA_patients']]\n",
    "            pmm_pmn = [len(self.patientToGenes[p]) for p in partition_stats['PMM_patients']]\n",
    "\n",
    "            if do_KS:\n",
    "                poisson_cdf.mu = self.lam[i]\n",
    "                partition_stats['KS'] = stats.kstest(dna_pmn, poisson_cdf)\n",
    "\n",
    "            #qq plot of the dna and then the poisson\n",
    "            poisson_q = get_quantiles(dna_pmn, pmm_pmn)\n",
    "            dna_q = get_quantiles(dna_pmn, dna_pmn)\n",
    "\n",
    "            plot_pmm_clusters(self.patientToGenes, {'PMM': partition_stats['PMM_patients'], 'DNA': partition_stats['DNA_patients'] },\n",
    "                              2, num_bins=100, title='DNA VS PMN')\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(dna_q, poisson_q, 'bo')\n",
    "            plt.plot([0, 100], [0,100], 'r-', label = 'y=x')\n",
    "            plt.title('QQ for ' + str(self.classes[i]), fontsize=20)\n",
    "            plt.xlabel('DNA_Q', fontsize=20)\n",
    "            plt.ylabel('PMM_Q', fontsize=20)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            partition_stats_list.append(partition_stats)\n",
    "\n",
    "        if do_KS:\n",
    "            self.data['KS_geom_mean'] = mex.prod([partition_stats['KS'][1] for partition_stats in partition_stats_list]) ** (1.0/ len(partition_stats_list))\n",
    "\n",
    "            print \"KS average is \", self.data['KS_geom_mean']\n",
    "            \n",
    "        self.data['CohenKappa'] = cohen_kappa(pmm_cluster_list, dna_cluster_list)\n",
    "\n",
    "\n",
    "        return partition_stats_list\n",
    "\n",
    "\n",
    "\n",
    "def cohen_kappa(cluster_list_1, cluster_list_2):\n",
    "    # assume same categories each\n",
    "    num_agree = 0\n",
    "    prob_agree = 0\n",
    "    total = len(set.union(*[set(c) for c in cluster_list_1]))\n",
    "    \n",
    "    num_classes = len(cluster_list_1)\n",
    "    \n",
    "    cluster_list_1 = [set(c) for c in cluster_list_1]\n",
    "    cluster_list_2 = [set(c) for c in cluster_list_2]\n",
    "    \n",
    "    for k in range(num_classes):\n",
    "        a = cluster_list_1[k]\n",
    "        b = cluster_list_2[k]\n",
    "        num_agree += len(a.intersection(b))\n",
    "        prob_agree += (len(a) * len(b) * 1.0) / (total ** 2)\n",
    "    \n",
    "\n",
    "    obs_agree = num_agree * 1.0 / total\n",
    "    \n",
    "    ck = (obs_agree - prob_agree)/(1.0 - prob_agree)\n",
    "    \n",
    "    print \"Number agreements \", num_agree\n",
    "    print \"Total \", total\n",
    "    print \"Prob agreements \", prob_agree\n",
    "    print \"Cohen kappa \", ck\n",
    "    \n",
    "    return ck\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def poisson_cdf(x):\n",
    "    if not hasattr(poisson_cdf, 'mu'):\n",
    "        poisson_cdf.mu = 0\n",
    "    print \"X is \", x, \"and mu is \", poisson_cdf.mu\n",
    "    return poisson.cdf(x, poisson_cdf.mu)\n",
    "\n",
    "def get_quantiles(test_dist, base_dist):\n",
    "    return [stats.percentileofscore(base_dist, t) for t in test_dist]\n",
    "\n",
    "def assign_missing(clusterToPatient, patientToGenes):\n",
    "    if -1 not in clusterToPatient:\n",
    "        print \"No missing patients in clusters\"\n",
    "        return clusterToPatient\n",
    "    missing_patients = clusterToPatient[-1]\n",
    "    cluster_means = [(sum([len(patientToGenes[p]) for p in clusterToPatient[c]]) * 1.0 /len(clusterToPatient[c]), c) for c in clusterToPatient if c != -1]\n",
    "    print cluster_means, cluster_means[0][0]\n",
    "    for patient in missing_patients:\n",
    "        num = len(patientToGenes[patient])\n",
    "        correct_cluster = sorted(cluster_means, key=lambda entry: abs(num - entry[0]))[0][1]\n",
    "        clusterToPatient[correct_cluster].add(patient)\n",
    "    clusterToPatient.pop(-1)\n",
    "\n",
    "    return clusterToPatient\n",
    "\n",
    "\n",
    "\n",
    "def best_pmm(patientToGenes, num_components, max_iter=30, rand_num=5, far_rand_num=5, min_cluster_size=0,\n",
    "             plot_clusters=True):\n",
    "\n",
    "    data_record = []\n",
    "    lls_record = []\n",
    "\n",
    "    # Do normal\n",
    "    first_data, lls = partition_pmm(patientToGenes, num_components,  max_iter=max_iter, min_cluster_size=min_cluster_size)\n",
    "\n",
    "    data_record.append(first_data)\n",
    "    lls_record.append(lls)\n",
    "\n",
    "    # Do best rand init\n",
    "    for i in range(rand_num):\n",
    "        data, lls = partition_pmm(patientToGenes, num_components, rand_init=True, max_iter=max_iter, min_cluster_size=min_cluster_size,\n",
    "                                 verbose=False)\n",
    "        data_record.append(data)\n",
    "        lls_record.append(lls)\n",
    "\n",
    "    for i in range(far_rand_num):\n",
    "        data, lls = partition_pmm(patientToGenes, num_components, far_rand_init=True, max_iter=max_iter, min_cluster_size=min_cluster_size,\n",
    "                                 verbose=False)\n",
    "        data_record.append(data)\n",
    "        lls_record.append(lls)\n",
    "\n",
    "    combined_record = zip(data_record, lls_record)\n",
    "\n",
    "    combined_record = sorted(combined_record, key=lambda entry: (-1 * entry[0]['Missing'], entry[0]['Likelihood']), reverse=True)\n",
    "\n",
    "    data_record, lls_record = zip(*combined_record)\n",
    "\n",
    "    best_data = data_record[0]\n",
    "\n",
    "    if (best_data['Likelihood'] > first_data['Likelihood'] + 10):\n",
    "        print \"First data not best!\"\n",
    "        best_data['IsFirst'] = False\n",
    "    else:\n",
    "        best_data['IsFirst'] = True\n",
    "\n",
    "\n",
    "    clusterToPatient = pmm_to_cluster(patientToGenes, best_data['Classes'], best_data['Means'], best_data['Probabilities'])\n",
    "\n",
    "    if plot_clusters:\n",
    "        plot_pmm_clusters(patientToGenes, clusterToPatient, num_components)\n",
    "\n",
    "    plot_likelihoods(lls_record)\n",
    "\n",
    "    return best_data, clusterToPatient\n",
    "    # Return clusters\n",
    "\n",
    "\n",
    "def pmm_to_cluster(patientToGenes, classes, lam, p_k):\n",
    "    clusterToPatient = {}\n",
    "\n",
    "    for k in classes:\n",
    "        clusterToPatient[k] = set()\n",
    "\n",
    "    clusterToPatient[-1] = set()\n",
    "\n",
    "\n",
    "    for patient in patientToGenes:\n",
    "        d = len(patientToGenes[patient])\n",
    "\n",
    "        max_class = -1\n",
    "        max_ll = -np.inf\n",
    "        for k in classes:\n",
    "            if (np.log(p_k[k]) + np.log(poisson(lam[k]).pmf(d))) > -np.inf:\n",
    "                if (np.log(p_k[k]) + np.log(poisson(lam[k]).pmf(d))) > max_ll:\n",
    "                    max_class = k\n",
    "                    max_ll = (np.log(poisson(lam[k]).pmf(d)))\n",
    "\n",
    "\n",
    "        clusterToPatient[max_class].add(patient)\n",
    "\n",
    "    missing_clusters = set()\n",
    "    for cluster in clusterToPatient:\n",
    "        if not clusterToPatient[cluster]:\n",
    "            print '**********NO PATIENTS IN CLUSTER ', lam[cluster], p_k[cluster]\n",
    "            missing_clusters.add(cluster)\n",
    "            #clusterToPatient[cluster].add('NO PATIENTS IN CLUSTER')\n",
    "    for cluster in missing_clusters:\n",
    "        clusterToPatient.pop(cluster)\n",
    "            \n",
    "    return clusterToPatient\n",
    "\n",
    "\n",
    "\n",
    "def pmm_cross_validate(num_components, patientToGenes, num_folds, kf_random_state=None, max_iter=30, rand_num=5, far_rand_num=5, min_cluster_size=0):\n",
    "    \"\"\"\n",
    "    :return: The average likelihood of the model when applied to a new test set, and its BIC\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(len(patientToGenes), n_folds=num_folds, random_state=kf_random_state)\n",
    "\n",
    "    lls = []\n",
    "    missing_patients = []\n",
    "    bics = []\n",
    "    for train_index, test_index in kf:\n",
    "\n",
    "        train_patientToGenes = dict([patientToGenes.items()[x] for x in train_index])\n",
    "        test_patientToGenes = dict([patientToGenes.items()[x] for x in test_index])\n",
    "        best_data, _ = best_pmm(train_patientToGenes, num_components, max_iter=max_iter, rand_num=rand_num,\n",
    "                                               far_rand_num=far_rand_num, min_cluster_size=min_cluster_size)\n",
    "\n",
    "        test_stats, test_cluster = pmm_fit_to_data(test_patientToGenes, best_data['Classes'], best_data['Means'], best_data['Probabilities'])\n",
    "\n",
    "        plot_pmm_clusters(test_patientToGenes, test_cluster, num_components, title='Test clusters size ' + str(num_components))\n",
    "\n",
    "        lls.append(test_stats['Likelihood'])\n",
    "        missing_patients.append(test_stats['Missing'])\n",
    "        bics.append(test_stats['BIC'])\n",
    "\n",
    "    return sum(lls) * 1.0/len(lls), sum(missing_patients) * 1.0 / len(missing_patients), sum(bics) * 1.0/ len(bics)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pmm_fit_to_data(patientToGenes, classes, lam, p_k, data=None, min_cluster_size=0):\n",
    "    \"\"\"\n",
    "    :param patientToGenes:\n",
    "    :param lam:\n",
    "    :param p_k:\n",
    "    :param data:\n",
    "    :return: data, clusterToPatient\n",
    "    \"\"\"\n",
    "\n",
    "    if not data:\n",
    "        data = collections.OrderedDict()\n",
    "\n",
    "\n",
    "    D = [len(patientToGenes[p]) for p in patientToGenes]\n",
    "    numCases = len(D)\n",
    "    num_components = len(lam)\n",
    "\n",
    "    ll_kd = np.array([ [np.log(p_k[k]) + np.log(poisson(lam[k]).pmf(d)) for d in D] for k in classes])\n",
    "    likelihood_sums = np.zeros(numCases)\n",
    "\n",
    "    for i in range(numCases):\n",
    "        likelihood_sums[i] = sum([(np.exp(ll_kd[k][i]) if ll_kd[k][i] > -np.inf else 0) for k in range(num_components)] )\n",
    "\n",
    "    # complete log likelihood\n",
    "\n",
    "    ll = sum(np.log(np.array([ls for ls in likelihood_sums if ls > 0])))\n",
    "\n",
    "    clusterToPatient = pmm_to_cluster(patientToGenes, classes, lam, p_k)\n",
    "\n",
    "    print \"LL:\", np.round(ll), \"Missing patients: \", len(clusterToPatient[-1]) if -1 in clusterToPatient else 0\n",
    "\n",
    "    data['Number'] = num_components\n",
    "    data['OriginalNumber'] = num_components\n",
    "    mp = zip(*sorted(zip(list(np.round(lam, 1)), list(np.round(p_k, 2))), key = lambda entry: entry[0]))\n",
    "\n",
    "    data['Means'], data['Probabilities'] =  list(mp[0]), list(mp[1])   \n",
    "    data['Likelihood'] = np.round(ll)\n",
    "    data['Classes'] = classes\n",
    "    data['AIC'] = np.round(2 * (len(p_k) + len(lam)) - 2 * ll)\n",
    "    data['BIC'] = np.round(-2 * ll + (len(p_k) + len(lam)) * np.log(numCases))\n",
    "    data['Missing'] = len(clusterToPatient[-1]) if -1 in clusterToPatient else 0\n",
    "    data['MinClusterSize'] = min([len(clusterToPatient[c]) if c != -1 else np.inf  for c in clusterToPatient])\n",
    "    data['MoreThanMin'] = 1 if data['MinClusterSize'] > min_cluster_size else 0\n",
    "    data['Merged'] = False\n",
    "    data['MergeHistory'] = set()\n",
    "\n",
    "    return data, clusterToPatient\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def partition_pmm(patientToGenes, num_components, diff_thresh=0.01, num_bins=50, max_iter=100, by_iter=True,\n",
    "                  rand_init=False, far_rand_init=False, do_plot=False, get_best=True, min_cluster_size=0,\n",
    "                 verbose=True):\n",
    "\n",
    "\n",
    "    # get the whole data distribution\n",
    "\n",
    "\n",
    "    # D = [1,2,3,4,5, 100, 150, 200, 1000]\n",
    "    D = [len(patientToGenes[p]) for p in patientToGenes]\n",
    "    numCases = len(D)\n",
    "    data = collections.OrderedDict()\n",
    "\n",
    "    # print \"D is \", D\n",
    "\n",
    "    # get the lambdas at equal-spaced intervals\n",
    "\n",
    "\n",
    "    lam = [np.percentile(D, (i + 1) * 100.0 / (num_components + 1)) for i in range(num_components)]\n",
    "    p_k = [1.0 / num_components for i in range(num_components)]\n",
    "    classes = range(num_components)\n",
    "\n",
    "    if rand_init:\n",
    "        old_lam = lam\n",
    "        old_p_k = p_k\n",
    "        #random sample  in a range centered at the quartiles\n",
    "        lam = [np.random.uniform(l - 0.5 * old_lam[0], l + 0.5 * old_lam[0]) for l in old_lam]\n",
    "        rand_freq = [2**np.random.uniform(-1, 1) * pk for pk in old_p_k]\n",
    "        p_k = list(np.array(rand_freq)/sum(rand_freq))\n",
    "        classes = range(num_components)\n",
    "\n",
    "    if far_rand_init:\n",
    "        lam = [np.random.uniform(min(D), max(D)) for l in lam]\n",
    "        rand_freq = [np.random.uniform(0, 1) for l in lam]\n",
    "        p_k = list(np.array(rand_freq)/sum(rand_freq))\n",
    "\n",
    "    if verbose:\n",
    "        print \"Initial Lambda is \", lam\n",
    "        print \"Initial p_k is\", p_k\n",
    "\n",
    "    data['Initial Means'] = np.round(lam,1)\n",
    "    data['Initial p_k'] = np.round(p_k, 2)\n",
    "\n",
    "    ll = -3e100\n",
    "    num_iter = 0\n",
    "\n",
    "    # stupid inital values\n",
    "    p_k_d= np.zeros(num_components)\n",
    "    lam_prev = np.zeros(num_components)\n",
    "    p_k_prev = np.zeros(num_components)\n",
    "\n",
    "    # for the best values\n",
    "    ll_best = -np.inf\n",
    "    p_k_best = None\n",
    "    lam_best = None\n",
    "    missing_best = numCases\n",
    "\n",
    "    lls = []\n",
    "\n",
    "    while 1:\n",
    "\n",
    "\n",
    "        # We have the log-likelihood of data d and class k in matrix\n",
    "        #            data 1 data 2 data 3\n",
    "        # clsss 1   ll_11   ll_12\n",
    "        # class 2\n",
    "        ll_kd = np.array([ [np.log(p_k[k]) + np.log(poisson(lam[k]).pmf(d)) for d in D] for k in classes])\n",
    "\n",
    "        \n",
    "\n",
    "        # Likelihood_sums: the total likelihood of each data, summed across class k\n",
    "        likelihood_sums = np.zeros(numCases)\n",
    "\n",
    "        for i in range(numCases):\n",
    "            likelihood_sums[i] = sum([(np.exp(ll_kd[k][i]) if ll_kd[k][i] > -np.inf else 0) for k in range(num_components)] )\n",
    "\n",
    "            \n",
    "        missing_new = len([x for x in likelihood_sums if x == 0])\n",
    "        # complete log likelihood\n",
    "\n",
    "        ll_new = sum(np.log(np.array([ls for ls in likelihood_sums if ls > 0])))\n",
    "\n",
    "        if num_iter == 0:\n",
    "            data['Initial LL'] = np.round(ll_new)\n",
    "\n",
    "        if verbose:\n",
    "            print \"ll_new is \", ll_new, \"missing is \", missing_new\n",
    "\n",
    "\n",
    "        if ll_new > ll_best or missing_new < missing_best:\n",
    "            ll_best = ll_new\n",
    "            p_k_best = p_k\n",
    "            lam_best = lam\n",
    "            missing_best = missing_new\n",
    "\n",
    "        # When we break out of the loop, take previous value since it might have jumped out\n",
    "        if (by_iter):\n",
    "            if num_iter > max_iter:\n",
    "                break\n",
    "            elif abs(ll_new - ll) < diff_thresh:\n",
    "                break\n",
    "        else:\n",
    "            if abs(ll_new - ll) < diff_thresh:\n",
    "\n",
    "                p_k_d = p_k_d_prev\n",
    "                lam = lam_prev\n",
    "                p_k = p_k_prev\n",
    "\n",
    "            break\n",
    "\n",
    "        p_k_d_prev = p_k_d\n",
    "        lam_prev = lam\n",
    "        p_k_prev = p_k\n",
    "\n",
    "\n",
    "        # Calculate p_k_d. This is p(data d | class k) * p(class k)/sum(p(data|class i) *p(class i);\n",
    "        # i.e. prob of this class given this data\n",
    "\n",
    "        p_k_d = np.zeros(ll_kd.shape)\n",
    "\n",
    "        for i in range(numCases):\n",
    "            # Use max class likelihood to divide all the likelihoods by\n",
    "            max_val = np.amax(ll_kd, axis=0)[i]\n",
    "\n",
    "            # sum the likekhoods for every class, make this the denominator of probability\n",
    "            denom = sum([(np.exp(ll_kd[k][i] - max_val) if ll_kd[k][i] > -np.inf else 0) for k in range(num_components)])\n",
    "\n",
    "            for k in range(num_components):\n",
    "                p_k_d[k][i] = (np.exp(ll_kd[k][i] - max_val) / denom if ll_kd[k][i] > -np.inf else 0)\n",
    "                # print \"numerator is \", np.exp(ll_kd[k][i] - max), \" prob is \", p_k_d[k][i]\n",
    "\n",
    "        # print \"p_k_d is \", p_k_d\n",
    "\n",
    "        # sum probabilities of each data being each class over all data\n",
    "        Z_k = p_k_d.sum(axis=1)\n",
    "\n",
    "\n",
    "        # see derivation\n",
    "\n",
    "        lam = [sum([p_k_d[k][i] * D[i] for i in range(numCases)]) * 1.0 / Z_k[k] for k in classes]\n",
    "        p_k = Z_k * 1.0 / numCases\n",
    "\n",
    "        p_k = p_k/p_k.sum()\n",
    "\n",
    "\n",
    "        # print \"New lambda is \", lam\n",
    "        # print \"New p_k is \", p_k\n",
    "\n",
    "\n",
    "        ll = ll_new\n",
    "\n",
    "        lls.append(ll)\n",
    "        num_iter += 1\n",
    "\n",
    "\n",
    "\n",
    "    if get_best:\n",
    "        p_k = p_k_best\n",
    "        lam = lam_best\n",
    "        ll = ll_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data, clusterToPatient = pmm_fit_to_data(patientToGenes, classes, lam, p_k, data=data, min_cluster_size=min_cluster_size)\n",
    "    # plot patients in each cluster\n",
    "\n",
    "    if do_plot:\n",
    "        plot_pmm_clusters(patientToGenes, clusterToPatient, num_components, num_bins=100)\n",
    "\n",
    "\n",
    "    # clusterToPatient = pmm_to_cluster(patientToGenes, classes, lam, p_k)\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # data['Number'] = num_components\n",
    "    # data['Means'] = np.round(lam, 1)\n",
    "    # data['Probabilities'] = np.round(p_k, 2)\n",
    "    # data['Likelihood'] = np.round(ll)\n",
    "    # data['Classes'] = classes\n",
    "    # data['AIC'] = np.round(2 * (len(p_k) + len(lam)) - 2 * ll)\n",
    "    # data['BIC'] = np.round(-2 * ll + (len(p_k) + len(lam)) * np.log(numCases))\n",
    "    # data['Missing'] = len(clusterToPatient[-1]) if -1 in clusterToPatient else 0\n",
    "    # data['MinClusterSize'] = min([len(clusterToPatient[c]) if c != -1 else np.inf  for c in clusterToPatient])\n",
    "    # data['MoreThanMin'] = 1 if data['MinClusterSize'] > min_cluster_size else 0\n",
    "\n",
    "    return data, lls\n",
    "\n",
    "\n",
    "\n",
    "def sort_data_by_means(data):\n",
    "    \"\"\" Sort in ascending order. Don't need to change cluster labels\"\"\"\n",
    "    data_items = data.items()\n",
    "    mean_indices = ((i, data['Means'][i]) for i in range(len(data['Means'])))\n",
    "    mean_indices = sorted(mean_indices, key=lambda entry: min(entry[1]) if isinstance(entry[1], list)\n",
    "                         else entry[1])\n",
    "    \n",
    "    conversion_array = [m[0] for m in mean_indices] # this should map to the correct index now. these are new clusters\n",
    "    \n",
    "    new_data = collections.OrderedDict()\n",
    "    \n",
    "    for key in data:\n",
    "        value = data[key]\n",
    "        if isinstance(value, np.ndarray):\n",
    "            new_value = np.zeros(len(value))\n",
    "            for i in range(len(conversion_array)):\n",
    "                new_value[i] = value[conversion_array[i]]\n",
    "            new_data[key] = new_value\n",
    "        if isinstance(value, list):\n",
    "            new_value = [value[conversion_array[i]] for i in range(len(conversion_array))]\n",
    "            new_data[key] = new_value\n",
    "            \n",
    "        else:\n",
    "            new_data[key] = value\n",
    "    \n",
    "    return new_data\n",
    "    \n",
    "\n",
    "def merge_clusters(data, clusterToPatient, patientToGenes,\n",
    "                  missing_limit=0.5, min_cluster_size=30):\n",
    "    \"\"\"Merge adjacent clusters. Choosse to merge those clusters that\n",
    "    are the most similar, as measured by the likelihood of one within\n",
    "    another.\n",
    "    missing_limit is the limit on number of patients that can't\n",
    "    be explained by one cluster. Clusters will be sorted first\n",
    "    by those who are below the minimum cluster size,\n",
    "    less missing patients in their merging\n",
    "    cluster, then by those that have the highest likelihood\n",
    "    \"\"\"\n",
    "    # get the likelihood of each cluster rel. to other ones\n",
    "    # only look at adjacent clusters! sort them\n",
    "    \n",
    "    data = sort_data_by_means(data)\n",
    "    \n",
    "    print \"****************************************\"\n",
    "    print \"Begin merging.\"\n",
    "    # first go forward\n",
    "\n",
    "    \n",
    "    classes = data['Classes']\n",
    "    p_k = data['Probabilities']\n",
    "    lam = data['Means']\n",
    "    \n",
    "    \n",
    "    all_list = []\n",
    "    \n",
    "    for i in range(len(lam) - 1):\n",
    "        from_index, to_index = i, i + 1\n",
    "        from_class, to_class = classes[from_index], classes[to_index]\n",
    "        patients = clusterToPatient[from_class]\n",
    "        p = [len(patientToGenes[patient]) for patient in patients]\n",
    "        \n",
    "        #check if we're dealing with merged clusters. if so... add the likelihoods of the individual\n",
    "        # underlying poissons?\n",
    "        if isinstance(p_k[from_index], list):\n",
    "            clust_probs = p_k[from_index]\n",
    "            clust_means = lam[from_index]\n",
    "            clust_size = len(clust_means)\n",
    "            \n",
    "            from_ll = [max([np.log(clust_probs[x]) + \n",
    "                           np.log(poisson(clust_means[x]).pmf(d)) for x in range(clust_size)])\n",
    "                          for d in p]\n",
    "        else:\n",
    "            from_ll = [np.log(p_k[from_index]) + np.log(poisson(lam[from_index]).pmf(d)) for d in p]\n",
    "            \n",
    "        if isinstance(p_k[to_index], list):\n",
    "            clust_probs = p_k[to_index]\n",
    "            clust_means = lam[to_index]\n",
    "            clust_size = len(clust_means)\n",
    "            \n",
    "            to_ll = [max([np.log(clust_probs[x]) + \n",
    "                           np.log(poisson(clust_means[x]).pmf(d)) for x in range(clust_size)])\n",
    "                          for d in p]\n",
    "        else:\n",
    "            to_ll = [np.log(p_k[to_index]) + np.log(poisson(lam[to_index]).pmf(d)) for d in p]\n",
    "            \n",
    "        missing = np.isinf(from_ll) ^ np.isinf(to_ll)\n",
    "        \n",
    "        missing_indices = np.where(missing)[0]\n",
    "        good_indices = np.where(~missing)[0]\n",
    "        \n",
    "        missing_num = len(missing_indices)\n",
    "        \n",
    "        ll_diffs = [to_ll[j] - from_ll[j] for j in good_indices]\n",
    "        \n",
    "        ll_diffs_total = sum(ll_diffs)\n",
    "        \n",
    "        all_list.append([(from_index, to_index), missing_num, ll_diffs_total, missing_num > missing_limit * len(p),\n",
    "                        len(patients) < min_cluster_size])\n",
    "        \n",
    "    # now go backwards\n",
    "    for i in reversed(range(1, len(lam))):\n",
    "        from_index, to_index = i, i - 1\n",
    "        from_class, to_class = classes[from_index], classes[to_index]\n",
    "        patients = clusterToPatient[from_class]\n",
    "        p = [len(patientToGenes[patient]) for patient in patients]\n",
    "        \n",
    "                #check if we're dealing with merged clusters. if so... add the likelihoods of the individual\n",
    "        # underlying poissons?\n",
    "        if isinstance(p_k[from_index], list):\n",
    "            clust_probs = p_k[from_index]\n",
    "            clust_means = lam[from_index]\n",
    "            clust_size = len(clust_means)\n",
    "            \n",
    "            from_ll = [max([np.log(clust_probs[x]) + \n",
    "                           np.log(poisson(clust_means[x]).pmf(d)) for x in range(clust_size)])\n",
    "                          for d in p]\n",
    "        else:\n",
    "            from_ll = [np.log(p_k[from_index]) + np.log(poisson(lam[from_index]).pmf(d)) for d in p]\n",
    "            \n",
    "        if isinstance(p_k[to_index], list):\n",
    "            clust_probs = p_k[to_index]\n",
    "            clust_means = lam[to_index]\n",
    "            clust_size = len(clust_means)\n",
    "            \n",
    "            to_ll = [max([np.log(clust_probs[x]) + \n",
    "                           np.log(poisson(clust_means[x]).pmf(d)) for x in range(clust_size)])\n",
    "                          for d in p]\n",
    "        else:\n",
    "            to_ll = [np.log(p_k[to_index]) + np.log(poisson(lam[to_index]).pmf(d)) for d in p]\n",
    "        \n",
    "        \n",
    "        missing = np.isinf(from_ll) ^ np.isinf(to_ll)\n",
    "        \n",
    "        missing_indices = np.where(missing)[0]\n",
    "        good_indices = np.where(~missing)[0]\n",
    "        \n",
    "        missing_num = len(missing_indices)\n",
    "        \n",
    "        ll_diffs = [to_ll[j] - from_ll[j] for j in good_indices]\n",
    "        \n",
    "        ll_diffs_total = sum(ll_diffs)\n",
    "        \n",
    "        \n",
    "        all_list.append([(from_index, to_index), missing_num, ll_diffs_total, missing_num < missing_limit * len(p),\n",
    "                        len(patients) < min_cluster_size])\n",
    "        \n",
    "    \n",
    "    # sort by the cluster that's below the min size, then byminimum missing, then by maximum likelihood ratio\n",
    "    all_list = sorted(all_list, key=lambda entry: (entry[4], entry[3], entry[2]), reverse=True)\n",
    "    \n",
    "    print \"Possible merged clusters is \", all_list\n",
    "    print \"Best cluster is \", all_list[0]\n",
    "    \n",
    "\n",
    "    (from_index, to_index), missing_num, ll_diffs_total, more_than_missing, cluster_too_small = all_list[0]\n",
    "\n",
    "    # calculate the new AIC, BIC, make new cluster to patient, make new classes..new means? update probabilities\n",
    "    \n",
    "    # Record merge history\n",
    "    new_data = data\n",
    "    if 'MergeHistory' not in new_data:\n",
    "        new_data['MergeHistory'] = set()\n",
    "    \n",
    "    new_data['MergeHistory'].add((str([lam[from_index], lam[to_index]]),\n",
    "                  str([p_k[from_index], p_k[to_index]]),\n",
    "                  (len(clusterToPatient[classes[from_index]]), len(clusterToPatient[classes[to_index]])),\n",
    "                  missing_num, ll_diffs_total, ('Num classes befpre', len(classes), ('Cluster too small?', cluster_too_small))))\n",
    "        \n",
    "    new_clusterToPatient = clusterToPatient\n",
    "    moved_patients = new_clusterToPatient[classes[from_index]]\n",
    "    new_clusterToPatient[classes[to_index]] = new_clusterToPatient[classes[to_index]].union(moved_patients)\n",
    "    new_clusterToPatient.pop(classes[from_index])\n",
    "\n",
    "    \n",
    "    print \"MERGING the probs and likelihoods\"\n",
    "    if not isinstance(p_k[from_index], list):\n",
    "        p_k[from_index] = [p_k[from_index]]\n",
    "        lam[from_index] = [lam[from_index]]\n",
    "    if not isinstance(p_k[to_index], list):\n",
    "        p_k[to_index] = [p_k[to_index]]\n",
    "        lam[to_index] = [lam[to_index]] \n",
    "    p_k[to_index].extend(p_k[from_index])\n",
    "    lam[to_index].extend(lam[from_index])\n",
    "    new_data['Probabilities'] = p_k\n",
    "    new_data['Means'] = lam\n",
    "    \n",
    "    \n",
    "    print \"MERGING: HERE ARE OLD VALUES\", new_data\n",
    "    #remove all the old values\n",
    "    new_data['Merged'] = True\n",
    "    new_data['Number'] -= 1\n",
    "    for key in new_data:\n",
    "        value = new_data[key]\n",
    "        if isinstance(value, np.ndarray):\n",
    "            value = list(value)\n",
    "            value = value[0: from_index] + value[from_index + 1 :]\n",
    "            value = np.array(value)\n",
    "            new_data[key] = value\n",
    "        elif isinstance(value, list):\n",
    "            value = value[0: from_index] + value[from_index + 1 :]\n",
    "            new_data[key] = value\n",
    "\n",
    "    print \"New classe:\", new_data['Classes'], \"VS NEW KEYS\", new_clusterToPatient.keys()\n",
    "            \n",
    "    # integrate the old patients to the new ones\n",
    "\n",
    "    \n",
    "    \n",
    "    new_data['MinClusterSize'] = min(len(new_clusterToPatient[c]) for c in new_clusterToPatient)\n",
    "    \n",
    "    print \"MERGING: HERE ARE NEW VALUES\", new_data\n",
    "    \n",
    "    plot_pmm_clusters(patientToGenes, clusterToPatient, new_data['Number'], title='Merging')\n",
    "    \n",
    "    print \"End merging.\"\n",
    "    print \"****************************************\"    \n",
    "    \n",
    "    return new_data, new_clusterToPatient\n",
    " \n",
    "    \n",
    "#     data['Number'] = num_components\n",
    "#     data['Means'], data['Probabilities'] = zip(*sorted(zip(list(np.round(lam, 1)), list(np.round(p_k, 2))), key = lambda entry: entry[0]))\n",
    "#     data['Likelihood'] = np.round(ll)\n",
    "#     data['Classes'] = classes\n",
    "#     data['AIC'] = np.round(2 * (len(p_k) + len(lam)) - 2 * ll)\n",
    "#     data['BIC'] = np.round(-2 * ll + (len(p_k) + len(lam)) * np.log(numCases))\n",
    "#     data['Missing'] = len(clusterToPatient[-1]) if -1 in clusterToPatient else 0\n",
    "#     data['MinClusterSize'] = min([len(clusterToPatient[c]) if c != -1 else np.inf  for c in clusterToPatient])\n",
    "#     data['MoreThanMin'] = 1 if data['MinClusterSize'] > min_cluster_size else 0\n",
    "\n",
    "def backward_selection(data, clusterToPatient, patientToGenes, min_cluster_size = 30,\n",
    "                       max_components = 10):\n",
    "    \"\"\"Merge clusters until a criterion is satisfied. Missing patients are assumed to\n",
    "    be assigned already.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    merged_data = data\n",
    "    merged_cluster = clusterToPatient\n",
    "    \n",
    "    while (merged_data['Number'] > max_components or merged_data['MinClusterSize'] < min_cluster_size):\n",
    "        merged_data, merged_cluster = merge_clusters(merged_data, merged_cluster, patientToGenes,\n",
    "                                                    min_cluster_size = min_cluster_size)\n",
    "    \n",
    "    return merged_data, merged_cluster\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_pmm_clusters(patientToGenes, clusterToPatient, num_components, num_bins=100, title=None):\n",
    "    D = [len(patientToGenes[p]) for p in patientToGenes]\n",
    "\n",
    "    bins = range(0, max(list(D)), max(list(D))/num_bins)\n",
    "    plt.figure()\n",
    "    for cluster in clusterToPatient:\n",
    "        plt.hist([len(patientToGenes[p]) for p in clusterToPatient[cluster]], bins=bins, label=str(cluster), alpha = 1.0/num_components)\n",
    "    plt.xlabel('# Somatic Mutations In Tumor', fontsize=20)\n",
    "    plt.ylabel('Number of Samples', fontsize=20)\n",
    "    plt.legend()\n",
    "    if not title:\n",
    "        plt.title(\"Cluster size \" + str(num_components), fontsize=20)\n",
    "    else:\n",
    "        plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "def plot_likelihoods(ll_record):\n",
    "    plt.figure()\n",
    "    for i in range(len(ll_record)):\n",
    "        plt.plot(ll_record[i], label=str(i))\n",
    "    plt.title(\"Log-likelihood change in EM\", fontsize=20)\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "\n",
    "# If there are any patients that aren't assigned, i.e. in cluster -1\n",
    "# Throw them out?\n",
    "def load_patient_cohorts(partitionfile, patientToGenes, add_to_closest=True, delimiter='\\t'):\n",
    "    clusterToProp = {}\n",
    "\n",
    "    with open(partitionfile, 'rU') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for row in reader:\n",
    "            if (row[0] == 'Cluster'): break\n",
    "        # reader = csv.DictReader(csvfile, delimiter=delimiter)\n",
    "        # print \"begun dict reader\\n\"\n",
    "        for row in reader:\n",
    "            c = eval(row[0])\n",
    "            print c\n",
    "            clusterToProp[c] = {}\n",
    "            clusterToProp[c]['Mean'] = eval(row[1]) if row[1] else 0\n",
    "            clusterToProp[c]['Probability'] = eval(row[2]) if row[2] else 0\n",
    "            clusterToProp[c]['Patients'] = set(row[3:]) if row[3] else set()\n",
    "\n",
    "\n",
    "    if -1 in clusterToProp:\n",
    "        if add_to_closest:\n",
    "            other_cs = clusterToProp.keys()\n",
    "            other_cs.remove(-1)\n",
    "            print \"Removed \", clusterToProp[-1]\n",
    "            for patient in clusterToProp[-1]:\n",
    "                sims = [(abs(len(patientToGenes[patient]) - clusterToProp[c]['Mean']), c) for c in other_cs]\n",
    "                sims = sorted(sims, key = lambda entry: entry[0])\n",
    "                best_c = sims[0][1]\n",
    "                clusterToProp[best_c]['Patients'].add(patient)\n",
    "            print \"completed\"\n",
    "\n",
    "        clusterToProp.pop(-1)\n",
    "\n",
    "    sorted_clusters = sorted(clusterToProp.keys(), key = lambda entry: clusterToProp[entry]['Mean'])\n",
    "    \n",
    "    oldclusterToProp = clusterToProp.copy()\n",
    "    clusterToProp = {}\n",
    "    cohort_dict = {}\n",
    "    \n",
    "    for i in range(len(sorted_clusters)):\n",
    "        cohort_dict[i] = oldclusterToProp[sorted_clusters[i]]['Patients']\n",
    "        clusterToProp[i] = oldclusterToProp[sorted_clusters[i]]\n",
    "    \n",
    "    min_cohort = cohort_dict[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     for c in clusterToProp:\n",
    "#         cohort_dict[c] = clusterToProp[c]['Patients']\n",
    "#     min_cohort = cohort_dict[sorted(clusterToProp.keys(), key=lambda entry: clusterToProp[entry]['Mean'])[0]]\n",
    "\n",
    "    return cohort_dict, clusterToProp, min_cohort\n",
    "\n",
    "# INDEX BY LOSSES\n",
    "%matplotlib inline\n",
    "def run_partitions(mutationmatrix = None, #'/Users/jlu96/maf/new/OV_broad/OV_broad-cna-jl.m2',\n",
    "        patientFile = None, #'/Users/jlu96/maf/new/OV_broad/shared_patients.plst',\n",
    "        out_file = None, #'/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/OV_broad-cna-jl-PMM-crossval.txt',\n",
    "        partition_file = None, #'/Users/jlu96/maf/new/OV_broad/OV_broad-cna-jl.ppf',\n",
    "        load_pmm_file = None, #'/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/OV_broad-cna-jl-PMM.txt',\n",
    "        dna_pmm_comparison_file = None, #'/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/OV_broad-cna-jl-PMM-dnacomp.txt',\n",
    "        cluster_matrix = None, # '/Users/jlu96/maf/new/OV_broad/OV_broad-cna-jl-cluster.m2',\n",
    "        min_cluster_size = 15,\n",
    "        num_init = 9,\n",
    "        minComp = 2,\n",
    "        maxComp = 5,\n",
    "        do_plot = True,\n",
    "        do_gmm = False,\n",
    "        do_dna = False,\n",
    "        num_integrated = 4,\n",
    "        do_kmeans = False,\n",
    "        do_pmm = True,\n",
    "        do_cross_val = False,\n",
    "        do_pmm_dna = True,\n",
    "        do_back_selection = True,\n",
    "        write_cluster_matrices = True,\n",
    "        rand_num = 3,\n",
    "        far_rand_num = 3,\n",
    "        kf_random_state = 1,\n",
    "        kf_num_folds = 5,\n",
    "\n",
    "        geneFile = None,\n",
    "        minFreq = 0,\n",
    "        dna_gene_file = '/Users/jlu96/conte/jlu/Analyses/CancerGeneAnalysis/DNADamageRepair_loss.txt',\n",
    "       out_dir = '/Users/jlu96/conte/jlu/Analyses/CancerMutationDistributions/',\n",
    "        write_all_partitions = True):\n",
    "    \n",
    "    mutationmatrix_list = mutationmatrix.split('/')\n",
    "    matrix_dir = '/'.join(mutationmatrix_list[:-1]) + '/'\n",
    "    prefix = (mutationmatrix_list[-1]).split('.m2')[0]\n",
    "    \n",
    "\n",
    "    if not patientFile:\n",
    "        patientFile = matrix_dir + 'shared_patients.plst'\n",
    "        \n",
    "    if not out_file:\n",
    "        if do_cross_val:\n",
    "            out_file = out_dir + prefix + '-PMM-crossval-kf' + str(kf_num_folds) + '.txt'\n",
    "        else:\n",
    "            out_file = out_dir + prefix + '-PMM-comparisons.txt'\n",
    "    \n",
    "    if not partition_file:\n",
    "        partition_file = matrix_dir + prefix + '.ppf'\n",
    "        \n",
    "    \n",
    "    if not load_pmm_file:\n",
    "        load_pmm_file = out_dir + prefix + '-PMM.txt'\n",
    "    \n",
    "    if not dna_pmm_comparison_file:\n",
    "        dna_pmm_comparison_file = out_dir + prefix + '-PMM-dnacomp.txt'\n",
    "        \n",
    "    if not cluster_matrix:\n",
    "        cluster_matrix = matrix_dir + prefix + '-cluster.m2'\n",
    "\n",
    "    \n",
    "    numGenes, numCases, genes, patients, geneToCases, patientToGenes = mex.load_mutation_data(mutationmatrix, patientFile, geneFile, minFreq)\n",
    "\n",
    "    p_gene_list = []\n",
    "\n",
    "    with open(dna_gene_file, 'rU') as row_file:\n",
    "        reader = csv.reader(row_file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            p_gene_list.append(row[0])\n",
    "        dna_cohort_dict = partition_gene_list(patientToGenes, p_gene_list, binary=not bool(num_integrated))\n",
    "\n",
    "\n",
    "    if do_kmeans:\n",
    "        datas = []\n",
    "        for i in np.arange(minComp, maxComp, 1):\n",
    "            datas.append(partition_gene_kmeans(geneToCases, patientToGenes, p_gene_list, i, num_bins=50, title=None, do_plot=True))\n",
    "\n",
    "        with open(out_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=datas[0].keys())\n",
    "            writer.writeheader()\n",
    "            for row in datas:\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    if do_dna:\n",
    "        cohort_dict = partition_gene_list(patientToGenes, p_gene_list, binary=not bool(num_integrated))\n",
    "        # Make new cohorts over this\n",
    "        if num_integrated:\n",
    "            cohort_dict = integrate_cohorts(cohort_dict, numCases, num_integrated)\n",
    "\n",
    "\n",
    "        cohort_pairings = [(key, cohort_dict[key]) for key in cohort_dict]\n",
    "        draw_partitions_cohorts(geneToCases, patientToGenes, cohort_pairings, title='DNADamageGenes',\n",
    "                        num_bins=100 if mutationmatrix[-9:] == 'cna-jl.m2' else 50)\n",
    "\n",
    "\n",
    "    if do_gmm:\n",
    "        datas = []\n",
    "        for i in np.arange(minComp, maxComp, 1):\n",
    "            datas.append(partition_GMM(patientToGenes, i, num_bins=50, title='GMM size ' + str(i), do_plot=do_plot))\n",
    "\n",
    "        with open(out_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=datas[0].keys())\n",
    "            writer.writeheader()\n",
    "            for row in datas:\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "    if do_pmm:\n",
    "        datas = []\n",
    "        clusters = []\n",
    "\n",
    "        partition_stats_list = []\n",
    "        for num_components in np.arange(minComp, maxComp, 1):\n",
    "            best_data, clusterToPatient = best_pmm(patientToGenes, num_components, rand_num=rand_num, far_rand_num=far_rand_num,\n",
    "                                                   min_cluster_size=min_cluster_size)\n",
    "\n",
    "            if do_back_selection:\n",
    "                # assign the missing data\n",
    "                clusterToPatient = assign_missing(clusterToPatient, patientToGenes)\n",
    "                best_data, clusterToPatient = backward_selection(best_data, clusterToPatient, patientToGenes, min_cluster_size = min_cluster_size,\n",
    "                       max_components = maxComp)\n",
    "            \n",
    "            if do_pmm_dna:\n",
    "                print \"cfirst lasses are \", best_data['Classes'], \"clusterToPatient is \", clusterToPatient.keys()\n",
    "                pmm = PMM(lam=best_data['Means'], p_k=best_data['Probabilities'], patientToGenes=patientToGenes,\n",
    "                         data=best_data, clusterToPatient=clusterToPatient, classes=best_data['Classes'],\n",
    "                          do_fit=False)\n",
    "\n",
    "                partition_stats_list.extend(pmm.compare_dna(dna_cohort_dict))\n",
    "\n",
    "                best_data = pmm.data\n",
    "\n",
    "\n",
    "            if do_cross_val:\n",
    "            #cross validate each of the components\n",
    "                print \"*******************************************************************************************************\"\n",
    "                print \"BEGINNING CROSS VALIDATION for \", num_components\n",
    "                print \"*******************************************************************************************************\"\n",
    "                best_data['TestLL'], best_data['TestMissing'], best_data['TestBIC'] = pmm_cross_validate(num_components, patientToGenes,\n",
    "                                                                                                         num_folds=kf_num_folds,\n",
    "                                                                                                     kf_random_state=kf_random_state,\n",
    "                                                                                   rand_num=rand_num, far_rand_num=far_rand_num,\n",
    "                                                                                   min_cluster_size=min_cluster_size)\n",
    "                best_data['TestFolds'] = kf_num_folds\n",
    "\n",
    "                print \"*******************************************************************************************************\"\n",
    "                print \"EMDING CROSS VALIDATION  for \", num_components\n",
    "                print \"*******************************************************************************************************\"\n",
    "\n",
    "            datas.append(best_data)\n",
    "            clusters.append(clusterToPatient)\n",
    "            \n",
    "            if write_all_partitions:\n",
    "                with open(partition_file + str(num_components), 'w') as csvfile:\n",
    "                    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "\n",
    "                    writer.writerow(['Likelihood', best_data['Likelihood']])\n",
    "                    writer.writerow(['BIC', best_data['BIC']])\n",
    "                    writer.writerow(['NumComponents', best_data['Number']])\n",
    "                    writer.writerow(['Cluster', 'Mean', 'Probability', 'Patients'])\n",
    "                    if 'Merged' in best_data and best_data['Merged']:\n",
    "                        for k in range(len(clusterToPatient)):\n",
    "                            lam = best_data['Means'][k]\n",
    "                            p_k = best_data['Probabilities'][k]\n",
    "                            writer.writerow([best_data['Classes'][k] , lam, p_k]  + list(clusterToPatient[best_data['Classes'][k]]))\n",
    "                        \n",
    "                    else:\n",
    "                        for k in clusterToPatient:\n",
    "                            if k != -1:\n",
    "                                lam = best_data['Means'][k]\n",
    "                                p_k = best_data['Probabilities'][k]\n",
    "                            else:\n",
    "                                lam = None\n",
    "                                p_k = None\n",
    "                            writer.writerow([k, lam, p_k] + list(clusterToPatient[k]))\n",
    "\n",
    "        # get the best BIC\n",
    "        combined = zip(datas, clusters)\n",
    "        if do_cross_val:\n",
    "            combined = sorted(combined, key=lambda entry: ( -1 * entry[0]['MoreThanMin'], np.round(entry[0]['TestMissing']), -1 * entry[0]['TestLL'], entry[0]['TestBIC'], entry[0]['BIC']))\n",
    "        else:\n",
    "            combined = sorted(combined, key=lambda entry: ( -1 * entry[0]['MoreThanMin'], entry[0]['BIC']))\n",
    "\n",
    "        datas, clusters = zip(*combined)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with open(out_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=datas[-1].keys(), delimiter='\\t', extrasaction='ignore')\n",
    "            print datas\n",
    "            writer.writeheader()\n",
    "            for row in datas:\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "        best_data = datas[0]\n",
    "        clusterToPatient = clusters[0]\n",
    "\n",
    "        # code to parition by best clusters\n",
    "        with open(partition_file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter='\\t')\n",
    "\n",
    "            writer.writerow(['Likelihood', best_data['Likelihood']])\n",
    "            writer.writerow(['BIC', best_data['BIC']])\n",
    "            writer.writerow(['NumComponents', best_data['Number']])\n",
    "            writer.writerow(['Cluster', 'Mean', 'Probability', 'Patients'])\n",
    "            if 'Merged' in best_data and best_data['Merged']:\n",
    "                for k in range(len(clusterToPatient)):\n",
    "                    lam = best_data['Means'][k]\n",
    "                    p_k = best_data['Probabilities'][k]\n",
    "                    writer.writerow([best_data['Classes'][k] , lam, p_k]  + list(clusterToPatient[best_data['Classes'][k]]))\n",
    "                        \n",
    "            else:\n",
    "                for k in clusterToPatient:\n",
    "                    if k != -1:\n",
    "                        lam = best_data['Means'][k]\n",
    "                        p_k = best_data['Probabilities'][k]\n",
    "                    else:\n",
    "                        lam = None\n",
    "                        p_k = None\n",
    "                    writer.writerow([k, lam, p_k] + list(clusterToPatient[k]))\n",
    "\n",
    "        if write_cluster_matrices:\n",
    "            for cluster in clusterToPatient:\n",
    "                with open(cluster_matrix + str(cluster), 'w') as csvfile:\n",
    "                    writer = csv.writer(csvfile, delimiter='\\t')\n",
    "                    for patient in clusterToPatient[cluster]:\n",
    "                        writer.writerow('\\t'.join([patient] + list(patientToGenes[patient])))\n",
    "\n",
    "\n",
    "        if do_pmm_dna:\n",
    "            with open(dna_pmm_comparison_file, 'w') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=partition_stats_list[0].keys(), delimiter='\\t')\n",
    "                writer.writeheader()\n",
    "                print \"header written\"\n",
    "                for row in partition_stats_list:\n",
    "                    writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
